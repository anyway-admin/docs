---
title: "Quickstart"
description: "Start tracing your AI applications in 5 minutes"
---

## Get Started

Follow these steps to instrument your first LLM application with Anyway.

<Steps>
  <Step title="Create an Account">
    Sign up at [webapp.anyway.sh](https://webapp.anyway.sh) and create your first project.

    Once logged in, navigate to **Settings** > **API Keys** and create a new API key.

    <Warning>
      Keep your API key secure. Never commit it to version control.
    </Warning>
  </Step>

  <Step title="Install the SDK">
    Install the Anyway Python SDK using pip (requires Python 3.10+):

    ```bash
    pip install anyway-sdk
    ```
  </Step>

  <Step title="Configure Environment">
    Set your collector endpoint and authentication:

    ```bash
    # Collector endpoint
    export TRACELOOP_BASE_URL="collector.anyway.sh:4317"

    # Authentication (URL-encoded)
    export TRACELOOP_HEADERS="Authorization=Bearer%20your-api-key"
    ```
  </Step>

  <Step title="Initialize the SDK">
    Initialize Traceloop in your application:

    ```python
    from anyway.sdk import Traceloop

    Traceloop.init(app_name="my-app")
    ```
  </Step>

  <Step title="Add Tracing Decorators">
    Use `@workflow` and `@task` decorators to trace your LLM operations:

    ```python
    from anyway.sdk import Traceloop
    from anyway.sdk.decorators import workflow, task
    from openai import OpenAI

    Traceloop.init(app_name="my-app")
    client = OpenAI()

    @task(name="call_openai")
    def call_openai(prompt: str) -> str:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content

    @workflow(name="answer_question")
    def answer_question(question: str) -> str:
        return call_openai(question)

    # Run it
    result = answer_question("What is observability?")
    print(result)
    ```
  </Step>

  <Step title="View Your Traces">
    Open the [Anyway Dashboard](https://webapp.anyway.sh) and navigate to **Traces**.

    You'll see your workflow and task spans with:
    - Execution hierarchy (workflow â†’ tasks)
    - Duration and timing for each operation
    - Request and response data
    - Token usage and cost estimates

    Click on any trace to see the full span tree.
  </Step>
</Steps>

## Understanding Workflows and Tasks

The SDK uses two decorators to structure your traces:

### @workflow

Use `@workflow` for high-level operations that orchestrate multiple steps:

```python
@workflow(name="process_document")
def process_document(doc: str):
    summary = summarize(doc)
    entities = extract_entities(doc)
    return {"summary": summary, "entities": entities}
```

### @task

Use `@task` for individual units of work:

```python
@task(name="summarize")
def summarize(text: str) -> str:
    response = client.chat.completions.create(...)
    return response.choices[0].message.content
```

### Async Support

Both decorators work seamlessly with async functions:

```python
@workflow(name="async_pipeline")
async def async_pipeline(query: str):
    result = await async_task(query)
    return result

@task(name="async_task")
async def async_task(query: str):
    response = await client.chat.completions.create(...)
    return response
```

## Next Steps

<CardGroup cols={2}>
  <Card title="SDK Configuration" icon="gear" href="/sdk/configuration">
    Configure endpoints, headers, and exporters.
  </Card>
  <Card title="Tracing LLM Calls" icon="route" href="/sdk/tracing">
    Detailed tracing examples for OpenAI and Anthropic.
  </Card>
  <Card title="Tracing Concepts" icon="route" href="/features/tracing">
    Learn about distributed tracing.
  </Card>
</CardGroup>

## Need Help?

<Card title="Contact Support" icon="headset" href="mailto:support@anyway.sh">
  Have questions? We're here to help.
</Card>
